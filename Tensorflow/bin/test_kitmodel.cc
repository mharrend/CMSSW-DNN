/*
 * Test of a KIT tensorflow model
 *
 * Graph created by Lukas Hilser using NNFlow Framework:
 *   Input:
 *     - name = "input:0", shape = (batch, 10)
 *   Output:
 *     - name = "output:0", shape = (batch, 1)
 *
 * Usage:
 *   > test_kitmodel
 *
 * Author:
 *   Marco A. Harrendorf
 *   Lukas Hilser
 */

#include <iostream>
#include <string>
#include <vector>

#include "DNN/Tensorflow/interface/Graph.h"
#include "DNN/Tensorflow/interface/Tensor.h"

int main(int argc, char* argv[])
{
    std::cout << std::endl
              << "test dnn::tf::Graph kitmodel" << std::endl;

    // get the file containing the graph
    std::string cmsswBase = std::string(getenv("CMSSW_BASE"));
    std::string dataDir = cmsswBase + "/src/DNN/Tensorflow/data";
    std::string graphFile = dataDir + "/kitmodel";
    std::cout << "load kitmodel graph " << graphFile << std::endl;

    //
    // object definitions
    //

    // load and initialize the graph
    dnn::tf::Graph g(graphFile, dnn::LogLevel::ALL);

    // prepare input and output tensors
    dnn::tf::Shape xShape[] = { 1, 239 };

    dnn::tf::Tensor* x = g.defineInput(new dnn::tf::Tensor("input:0", 2, xShape));
    dnn::tf::Tensor* y = g.defineOutput(new dnn::tf::Tensor("output:0"));

    //
    // evaluation
    //

    // fill a single batch of the input tensor with consecutive numbers
    std::vector<float> v = { 87.006111145, 707.873413086, 2.80770087242, 239.364151001, 135.168197632, -0.792131721973, 0.14802570641, 0.956407904625, 3.12125396729, 2.08568453789, 2.10590529442, 1.33594024181, 0.786055088043, 0.409592092037, 0.0544648133218, 0.20692242682, 0.0411505959928, 1216.34545898, 0.960932374001, 0.478305399418, 135.168197632, 0.55019813776, 0.984223544598, 0.151880353689, 0.000271461467491, 0.12004096061, 0.960932374001, 1.64506626129, 2.08083605766, 1.75152862072, 2.47030520439, 0.498706549406, 0.786055088043, 1.2904458046, 1.25474154949, 0.498706549406, 2.54302668571, 42.4768257141, 0.573103010654, 0.0993908420205, 0.78172570467, 0.416635841131, 707.873474121, 653.130065918, 0.478305399418, 1.84798038006, 223.402374268, 305.899871826, 195.609542847, 270.884063721, 27.7943820953, 3.97473955154, 378.134643555, 47.2732429504, 50.3640556335, 87.006111145, 135.168197632, 47.2732429504, -0.0111202914268, 13.817440033, 135.168197632, 1216.34545898, 10.5043010712, -0.583351075649, -1.6186568737, 12.4755096436, 180.102432251, 224.530014038, 180.102432251, 42.2678833008, 1.84798038006, 2.91093826294, 0.991725683212, 4.78629302979, 3.76524424553, 3.40108299255, 2.54284739494, 1.00987613201, 2.54284739494, 3.75431632996, 3.4222869873, 2.59696054459, 0.723395287991, 2.59696054459, 3.69875431061, 3.40184736252, 2.61900353432, 0.422756224871, 2.61900353432, 3.69875431061, 3.40184736252, 2.61900353432, 0.422756224871, 2.61900353432, 3.69875431061, 3.40184736252, 2.61900353432, 0.422756224871, 2.61900353432, 1.98295891285, 2.94648313522, 2.72415781021, 2.74484205246, 1.44342815876, 3.16293740273, 3.14140701294, 3.14140701294, 416.307678223, 416.307678223, 0.293836027384, 0.361133605242, 0.0229614600539, 0.0229614619166, 0.126668795943, 0.086583122611, 0.0956036150455, 0.0956036150455, 0.0119012175128, 0.0130067849532, 0.632518231869, 0.632518231869, 0.258474290371, 0.143608093262, 0.81811851263, 0.81811851263, 0.0281318891793, 0.0227818731219, 0.986530184746, 0.986530184746, 0.120690271258, 0.0548478662968, 0.507725536823, 5.77833234274e-05, 3.88050338529e-08, 0.752622783184, 0.776245474815, 7.93109029473e-06, 2.25188445668e-09, 2.2487269824e-09, 3.44082939918e-09, 4.89867674585e-17, 4.23920865685e-17, 2.70792313017e-08, 2.47497933259e-08, 3.00854853208e-18, 2.60353278004e-18, 3.27656493937e-06, 2.41190605266e-06, 2.45344326452e-13, 2.12315665808e-13, 0.000686306215357, 0.00142660178244, 0.000199665373657, 0.000199665373657, 0.00826451834291, 0.0102615077049, 1.22625560834e-05, 1.22625560834e-05, 0.000239226399572, 0.000239226399572, 0.000898111844435, 0.000898111844435, 3.26157489905e-10, 3.26157489905e-10, 5.1783843131e-18, 4.48126130826e-18, 1.36338417178e-06, 1.36338417178e-06, 5.76585660998e-15, 4.98964747558e-15, 3.0, 3.0, 7.0, 1.0, 9.0, 0.0, 16.0, 1.0, 0.0, 3.0, 42.4768257141, 0.0993908420205, -0.0111202914268, -1.6186568737, 42.2678833008, 0.996446371078, 0.995291888714, 0.960932374001, 0.454793304205, 0.190134614706, 0.133747830987, 0.995291888714, 0.454793304205, 0.960932374001, 0.133747830987, 0.996446371078, 0.12004096061, 0.324049025774, 0.512857198715, -0.0172975044698, -0.64281129837, 0.0536402277648, -0.148203074932, 286.909484863, 339.507354736, 145.510726929, 101.375389099, 274.271362305, 139.378540039, 1.09628081322, 1.58318865299, -0.936178803444, -0.402654618025, 2.18507528305, 1.66355931759, 13.0930175781, 14.9688119888, 16.711353302, 9.29528713226, 11.6479492188, 8.70384693146, 0.340904206038, 2.01807045937, -2.3886218071, -2.223498106, -0.282716602087, 1.52588272095, 172.287231445, 133.645339966, 98.2536849976, 93.2835464478, 60.8685874939, 50.8846168518, 0.995784342289, 0.9601790905, 0.971427500248, 0.995011866093, 0.916770339012, 0.974333643913};
    x->setVector<float>(1, 0, v); // axis: 1, axis 0 (= batch dim) value: 0, vector: v

    // evaluation call
    // this does not return anything but changes the output tensor(s) in place which is faster
    g.eval();

    // some outputs
    std::cout << "rank : " << y->getRank() << std::endl;
    std::cout << "shape: ";
    for (int i = 0; i < y->getRank(); i++)
    {
        std::cout << y->getShape(i) << " ";
    }
    std::cout << std::endl;
    std::cout << "NN output value: " << y->getValue<float>(0, 0) << std::endl;

    //
    // cleanup
    //

    // remove tensors manually (you type 'new', you type 'delete')
    delete x;
    delete y;

    std::cout << std::endl
              << "done" << std::endl;

    return 0;
}
